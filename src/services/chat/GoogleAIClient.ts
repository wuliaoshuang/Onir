/**
 * è•¾å§†ç²¾å¿ƒæ„å»ºçš„ Google AI ä¸“ç”¨é€‚é…å™¨
 * âœ¨ è§£å†³ Google AI ä¸ OpenAI æ ¼å¼ä¸å…¼å®¹é—®é¢˜
 *
 * Google AI API æ ¼å¼å®Œå…¨ä¸åŒï¼š
 * - è®¤è¯: x-goog-api-key (ä¸æ˜¯ Authorization: Bearer)
 * - ç«¯ç‚¹: /v1beta/models/{model}:streamGenerateContent
 * - è¯·æ±‚: contents[{role, parts:[{text}]}] (ä¸æ˜¯ messages[{role, content}])
 * - å“åº”: candidates[{content:{parts:[{text}]}}] (ä¸æ˜¯ choices[{message:{content}}])
 * - è§’è‰²: model (ä¸æ˜¯ assistant)
 *
 * @example
 * ```ts
 * import { GoogleAIClient } from '@/services/chat'
 *
 * const client = new GoogleAIClient({
 *   apiKey: 'AIza...',
 *   model: 'gemini-2.5-flash',
 * })
 *
 * await client.chat(messages, callbacks, { temperature: 0.7 })
 * ```
 */

import type {
  ChatCompletionRequest,
  StreamCallbacks,
  ChatError,
} from './types'

// ========================================
// Google AI å®¢æˆ·ç«¯é…ç½®
// ========================================
export interface GoogleAIClientConfig {
  apiKey: string
  baseUrl?: string   // é»˜è®¤: https://generativelanguage.googleapis.com
}

// ========================================
// Google AI API è¯·æ±‚æ ¼å¼
// ========================================
interface GoogleContent {
  role: 'user' | 'model'
  parts: Array<{ text?: string; inline_data?: { mime_type: string; data: string } }>
}

interface GoogleGenerateContentRequest {
  contents: GoogleContent[]
  generationConfig?: {
    temperature?: number
    maxOutputTokens?: number
  }
}

// ========================================
// Google AI API å“åº”æ ¼å¼
// ========================================
interface GoogleCandidate {
  content?: {
    parts: Array<{ text?: string }>
    role: string
  }
  finishReason?: string
  index: number
}

interface GenerateContentResponse {
  candidates: GoogleCandidate[]
  usageMetadata?: {
    promptTokenCount: number
    candidatesTokenCount: number
    totalTokenCount: number
  }
  modelVersion?: string
  responseId?: string
}

// ========================================
// Google AI å®¢æˆ·ç«¯
// ========================================
export class GoogleAIClient {
  private readonly apiKey: string
  private readonly baseUrl: string

  constructor(config: GoogleAIClientConfig) {
    this.apiKey = config.apiKey
    this.baseUrl = config.baseUrl || 'https://generativelanguage.googleapis.com'

    console.log(`ğŸ” è•¾å§†è°ƒè¯•ï¼šGoogleAIClient åˆå§‹åŒ– - baseUrl=${this.baseUrl}`)
  }

  /**
   * æ„å»º API endpoint URL
   * æ ¼å¼: /v1beta/models/{model}:streamGenerateContent
   */
  private buildEndpoint(model: string): string {
    // ç§»é™¤å°¾éƒ¨æ–œæ 
    const baseUrl = this.baseUrl.replace(/\/$/, '')
    return `${baseUrl}/v1beta/models/${model}:streamGenerateContent`
  }

  /**
   * æ„å»ºè¯·æ±‚å¤´
   * Google AI ä½¿ç”¨ x-goog-api-key header
   */
  private buildHeaders(): HeadersInit {
    return {
      'Content-Type': 'application/json',
      'x-goog-api-key': this.apiKey,
    }
  }

  /**
   * è½¬æ¢ OpenAI æ ¼å¼çš„æ¶ˆæ¯ä¸º Google AI æ ¼å¼
   *
   * OpenAI: { role: 'assistant', content: '...' }
   * Google: { role: 'model', parts: [{ text: '...' }] }
   */
  private convertMessagesToGoogleContents(
    messages: Array<{ role: string; content: string }>
  ): GoogleContent[] {
    return messages.map((msg) => ({
      role: msg.role === 'assistant' ? 'model' : ('user' as const),
      parts: [{ text: msg.content }],
    }))
  }

  /**
   * å‘é€æµå¼èŠå¤©è¯·æ±‚
   *
   * @param messages - OpenAI æ ¼å¼çš„æ¶ˆæ¯å†å²
   * @param callbacks - æµå¼å›è°ƒå‡½æ•°
   * @param options - å¯é€‰å‚æ•°ï¼ˆç³»ç»Ÿæç¤ºè¯ã€æ¸©åº¦ã€æ¨¡å‹ç­‰ï¼‰
   */
  async chat(
    messages: Array<{ role: string; content: string }>,
    callbacks: StreamCallbacks,
    options?: {
      systemPrompt?: string
      temperature?: number
      maxTokens?: number
      model?: string
    }
  ): Promise<void> {
    try {
      const model = options?.model || 'gemini-2.5-flash'
      const url = this.buildEndpoint(model)
      const headers = this.buildHeaders()

      console.log(`ğŸ” è•¾å§†è°ƒè¯•ï¼šGoogle AI å‘é€è¯·æ±‚ - url=${url}, model=${model}`)

      // è½¬æ¢æ¶ˆæ¯æ ¼å¼
      const googleContents = this.convertMessagesToGoogleContents(messages)

      // å¦‚æœæœ‰ç³»ç»Ÿæç¤ºè¯ï¼Œæ’å…¥åˆ°å¼€å¤´ï¼ˆä½œä¸ºç¬¬ä¸€æ¡ user æ¶ˆæ¯ï¼‰
      let finalContents = googleContents
      if (options?.systemPrompt) {
        finalContents = [
          {
            role: 'user' as const,
            parts: [{ text: `ç³»ç»ŸæŒ‡ä»¤ï¼š${options.systemPrompt}` }],
          },
          ...googleContents,
        ]
      }

      const requestBody: GoogleGenerateContentRequest = {
        contents: finalContents,
        generationConfig: {
          temperature: options?.temperature ?? 0.7,
          maxOutputTokens: options?.maxTokens ?? 4096,
        },
      }

      console.log('ğŸ” è•¾å§†è°ƒè¯•ï¼šGoogle AI è¯·æ±‚ä½“ =', JSON.stringify(requestBody, null, 2))

      const response = await fetch(url, {
        method: 'POST',
        headers,
        body: JSON.stringify(requestBody),
      })

      if (!response.ok) {
        await this.handleError(response)
      }

      await this.processStream(response, callbacks)
    } catch (error) {
      callbacks.onError(error as Error)
    }
  }

  /**
   * å¤„ç† SSE æµå¼å“åº”
   *
   * Google AI çš„æµå¼å“åº”ç‰¹ç‚¹:
   * - è¿”å›ä¸€ä¸ªå®Œæ•´çš„ JSON æ•°ç»„: [{...}, {...}, ...]
   * - æ•°ç»„å¯èƒ½è¢«ç½‘ç»œåˆ†å—ä¼ è¾“ï¼Œéœ€è¦ç´¯ç§¯åˆ°å®Œæ•´æ‰èƒ½è§£æ
   * - æ–‡æœ¬å†…å®¹åœ¨ candidates[0].content.parts[0].text
   * - finishReason: "STOP" è¡¨ç¤ºå®Œæˆ
   *
   * å¤„ç†ç­–ç•¥:
   * 1. ç´¯ç§¯æ‰€æœ‰æ¥æ”¶åˆ°çš„æ•°æ®
   * 2. å°è¯•è§£æä¸ºå®Œæ•´çš„ JSON æ•°ç»„
   * 3. è§£ææˆåŠŸåï¼Œä½¿ç”¨æ‰“å­—æœºæ•ˆæœé€ä¸ªå¤„ç†å…ƒç´ 
   */
  private async processStream(
    response: Response,
    callbacks: StreamCallbacks
  ): Promise<void> {
    const reader = response.body?.getReader()
    if (!reader) {
      throw new Error('æ— æ³•è·å–å“åº”æµ')
    }

    const decoder = new TextDecoder('utf-8')
    let buffer = ''
    let chunkCount = 0

    try {
      while (true) {
        const { done, value } = await reader.read()
        if (done) {
          console.log(`ğŸ” è•¾å§†è°ƒè¯•ï¼šæµç»“æŸï¼Œå…±æ¥æ”¶ ${chunkCount} ä¸ª chunk`)
          break
        }

        chunkCount++
        const chunkText = decoder.decode(value, { stream: true })
        buffer += chunkText

        console.log(`ğŸ” è•¾å§†è°ƒè¯•ï¼šchunk #${chunkCount}ï¼Œæ–°å¢ ${chunkText.length} å­—ç¬¦ï¼Œbuffer æ€»è®¡ ${buffer.length} å­—ç¬¦`)

        // å°è¯•è§£æ buffer ä¸º JSON
        try {
          const parsed = JSON.parse(buffer)

          if (Array.isArray(parsed)) {
            console.log(`âœ… è•¾å§†è°ƒè¯•ï¼šæˆåŠŸè§£æ JSON æ•°ç»„ï¼Œ${parsed.length} ä¸ªå…ƒç´ ï¼Œå‡†å¤‡ç”¨æ‰“å­—æœºæ•ˆæœè¾“å‡º`)
            // ä½¿ç”¨æ‰“å­—æœºæ•ˆæœå¤„ç†æ•°ç»„ä¸­çš„æ¯ä¸ªå…ƒç´ 
            await this.processArrayWithTypewriterEffect(parsed, callbacks)
            buffer = ''
          } else if (parsed && typeof parsed === 'object') {
            console.log('âœ… è•¾å§†è°ƒè¯•ï¼šæˆåŠŸè§£æ JSON å¯¹è±¡')
            if (this.processResponseItem(parsed, callbacks)) {
              return
            }
            buffer = ''
          }
        } catch (parseError) {
          // JSON è¿˜ä¸å®Œæ•´ï¼Œç»§ç»­ç´¯ç§¯æ•°æ®
          const errMsg = (parseError as Error).message
          // åªåœ¨ç¬¬ä¸€æ¬¡å’Œå¶å°”æ‰“å°ï¼Œé¿å…æ—¥å¿—è¿‡å¤š
          if (chunkCount === 1 || chunkCount % 10 === 0) {
            console.log(`ğŸ” è•¾å§†è°ƒè¯•ï¼šJSON è§£æä¸­... (chunk ${chunkCount}, buffer=${buffer.length} å­—ç¬¦)`)
          }
        }

        // é˜²æ­¢ buffer æ— é™å¢é•¿
        if (buffer.length > 500000) {
          console.warn('ğŸ” è•¾å§†è­¦å‘Šï¼šbuffer è¿‡å¤§ (>500KB)ï¼Œæ¸…ç©º')
          buffer = ''
        }
      }

      // æµç»“æŸï¼Œå°è¯•å¤„ç†å‰©ä½™æ•°æ®
      if (buffer.trim().length > 0) {
        console.log(`ğŸ” è•¾å§†è°ƒè¯•ï¼šæµç»“æŸï¼Œå°è¯•å¤„ç†å‰©ä½™ buffer (${buffer.length} å­—ç¬¦)`)
        try {
          const parsed = JSON.parse(buffer)
          if (Array.isArray(parsed)) {
            await this.processArrayWithTypewriterEffect(parsed, callbacks)
          } else if (parsed && typeof parsed === 'object') {
            this.processResponseItem(parsed, callbacks)
          }
        } catch (e) {
          console.error('âŒ è•¾å§†è°ƒè¯•ï¼šæœ€ç»ˆ buffer è§£æå¤±è´¥', e)
        }
      }

      console.log('ğŸ” è•¾å§†è°ƒè¯•ï¼šæµæ­£å¸¸ç»“æŸ')
      callbacks.onComplete()
    } catch (error) {
      console.error('âŒ è•¾å§†è°ƒè¯•ï¼šprocessStream é”™è¯¯ =', error)
      callbacks.onError(error as Error)
    } finally {
      reader.releaseLock()
    }
  }

  /**
   * ä½¿ç”¨æ‰“å­—æœºæ•ˆæœå¤„ç†æ•°ç»„å…ƒç´ 
   * æ¯ä¸ªå…ƒç´ ä¹‹é—´æ·»åŠ å°å»¶è¿Ÿï¼Œæ¨¡æ‹Ÿæµå¼è¾“å‡º
   * ğŸ¯ è•¾å§†ï¼šå¢åŠ å»¶è¿Ÿä»¥è·å¾—æ›´å¥½çš„é˜…è¯»ä½“éªŒ
   */
  private async processArrayWithTypewriterEffect(
    items: GenerateContentResponse[],
    callbacks: StreamCallbacks
  ): Promise<void> {
    const TYPING_DELAY = 120  // æ¯ä¸ªå…ƒç´ ä¹‹é—´çš„å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰- è•¾å§†è°ƒæ•´ä¸ºæ›´èˆ’é€‚çš„é˜…è¯»é€Ÿåº¦

    console.log(`ğŸ” è•¾å§†è°ƒè¯•ï¼šå¼€å§‹æ‰“å­—æœºæ•ˆæœï¼Œ${items.length} ä¸ªå…ƒç´ ï¼Œæ¯ä¸ªå»¶è¿Ÿ ${TYPING_DELAY}ms`)

    for (let i = 0; i < items.length; i++) {
      const item = items[i]

      if (this.processResponseItem(item, callbacks)) {
        console.log(`ğŸ” è•¾å§†è°ƒè¯•ï¼šå…ƒç´  [${i}] è§¦å‘å®Œæˆä¿¡å·ï¼Œåœæ­¢æ‰“å­—æœºæ•ˆæœ`)
        return
      }

      // æœ€åä¸€ä¸ªå…ƒç´ ä¸éœ€è¦å»¶è¿Ÿ
      if (i < items.length - 1) {
        await this.delay(TYPING_DELAY)
      }
    }

    console.log('âœ… è•¾å§†è°ƒè¯•ï¼šæ‰“å­—æœºæ•ˆæœå®Œæˆ')
  }

  /**
   * å»¶è¿Ÿå‡½æ•°
   */
  private delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms))
  }

  /**
   * å¤„ç†å•ä¸ªå“åº”é¡¹
   * @returns true è¡¨ç¤ºæ”¶åˆ°å®Œæˆä¿¡å·ï¼Œåº”è¯¥ç»“æŸæµ
   */
  private processResponseItem(
    data: GenerateContentResponse,
    callbacks: StreamCallbacks
  ): boolean {
    // æå–æ–‡æœ¬å†…å®¹
    const text = data.candidates?.[0]?.content?.parts?.[0]?.text

    if (text) {
      console.log(`âœ… è•¾å§†è°ƒè¯•ï¼šæ”¶åˆ°æ–‡æœ¬å—ï¼Œé•¿åº¦=${text.length}, å†…å®¹="${text.slice(0, 30)}..."`)
      callbacks.onChunk(text)
      return false  // ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªå…ƒç´ 
    }

    // æ£€æŸ¥æ˜¯å¦å®Œæˆ
    const finishReason = data.candidates?.[0]?.finishReason
    if (finishReason && finishReason !== 'IN_PROGRESS') {
      console.log(`âœ… è•¾å§†è°ƒè¯•ï¼šGoogle AI å®ŒæˆåŸå›  = ${finishReason}`)
      callbacks.onComplete()
      return true  // åº”è¯¥ç»“æŸæµ
    }

    return false
  }

  /**
   * ç»Ÿä¸€é”™è¯¯å¤„ç†
   */
  private async handleError(response: Response): Promise<never> {
    let errorMessage = 'è¯·æ±‚å¤±è´¥'
    let errorType = 'unknown_error'

    try {
      const errorData: ChatError = await response.json()
      errorMessage = errorData.error?.message || errorMessage
      errorType = errorData.error?.type || errorType
    } catch {
      errorMessage = response.statusText || errorMessage
    }

    // æ·»åŠ ä¾›åº”å•†ä¿¡æ¯åˆ°é”™è¯¯æ¶ˆæ¯
    errorMessage = `[Google AI] ${errorMessage}`
    throw new Error(errorMessage)
  }
}

// é‡æ–°å¯¼å‡ºç±»å‹
export type { ChatCompletionRequest, StreamCallbacks, ChatError } from './types'
