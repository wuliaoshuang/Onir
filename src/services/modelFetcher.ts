/**
 * è•¾å§†ç²¾å¿ƒè®¾è®¡çš„æ¨¡å‹è·å–æœåŠ¡
 * ä»å„ä¸ªä¾›åº”å•† API åŠ¨æ€è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
 */

import type { ProviderType } from '../types/apiKeys'

/**
 * æ¨¡å‹ä¿¡æ¯æ¥å£
 */
export interface ModelInfo {
  id: string
  name?: string
  description?: string
  context_length?: number
  // ğŸ¯ è•¾å§†ï¼šæ˜¯å¦ä¸ºæ¨ç†æ¨¡å‹ï¼ˆæ”¯æŒæ€è€ƒé“¾ï¼‰
  reasoning?: boolean
}

/**
 * æ¨¡å‹è·å–ç»“æœ
 */
export interface ModelsResult {
  success: boolean
  models: ModelInfo[]
  error?: string
}

/**
 * ğŸ¯ è•¾å§†ï¼šåˆ¤æ–­æ¨¡å‹æ˜¯å¦ä¸ºæ¨ç†æ¨¡å‹ï¼ˆæ”¯æŒæ€è€ƒé“¾ï¼‰
 * @param modelId æ¨¡å‹ ID
 */
function isReasoningModel(modelId: string): boolean {
  const lowerId = modelId.toLowerCase()

  // DeepSeek æ¨ç†æ¨¡å‹
  if (lowerId.includes('reasoner') || lowerId.includes('r1')) {
    return true
  }

  // OpenAI o1/o3 ç³»åˆ—æ¨ç†æ¨¡å‹
  if (lowerId.startsWith('o1-') || lowerId.startsWith('o3-')) {
    return true
  }

  // Google Gemini Thinking å’Œ Pro æ¨¡å‹ï¼ˆ2.5 Pro é»˜è®¤å¼€å¯æ€è€ƒé“¾ï¼‰
  if (lowerId.includes('thinking') || lowerId.includes('-pro') || lowerId.startsWith('gemini-2.5-pro')) {
    return true
  }

  return false
}

/**
 * ç»Ÿä¸€çš„æ¨¡å‹è·å–æœåŠ¡
 */
export class ModelFetcher {
  /**
   * è·å– DeepSeek å¯ç”¨æ¨¡å‹åˆ—è¡¨
   * API æ–‡æ¡£: https://api.deepseek.com/v1/models
   */
  static async fetchDeepSeekModels(apiKey: string): Promise<ModelsResult> {
    try {
      const response = await fetch('https://api.deepseek.com/v1/models', {
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json',
        },
      })

      if (!response.ok) {
        const error = await response.json().catch(() => ({}))
        return {
          success: false,
          models: [],
          error: error.error?.message || `HTTP ${response.status}`,
        }
      }

      const data = await response.json()

      // DeepSeek API è¿”å›æ ¼å¼: { object: 'list', data: [{ id, ... }] }
      const models: ModelInfo[] = (data.data || []).map((model: any) => ({
        id: model.id,
        reasoning: isReasoningModel(model.id),
      }))

      return {
        success: true,
        models,
      }
    } catch (error) {
      return {
        success: false,
        models: [],
        error: (error as Error).message || 'Network error',
      }
    }
  }

  /**
   * è·å– OpenAI å¯ç”¨æ¨¡å‹åˆ—è¡¨
   * API æ–‡æ¡£: https://platform.openai.com/docs/models
   */
  static async fetchOpenAIModels(apiKey: string): Promise<ModelsResult> {
    try {
      const response = await fetch('https://api.openai.com/v1/models', {
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json',
        },
      })

      if (!response.ok) {
        const error = await response.json().catch(() => ({}))
        return {
          success: false,
          models: [],
          error: error.error?.message || `HTTP ${response.status}`,
        }
      }

      const data = await response.json()

      // OpenAI API è¿”å›æ ¼å¼: { object: 'list', data: [{ id, ... }] }
      // è•¾å§†è¿‡æ»¤å‡ºèŠå¤©æ¨¡å‹
      const allModels = data.data || []
      const chatModels: ModelInfo[] = allModels
        .filter((model: any) => {
          const id = model.id as string
          return id.startsWith('gpt-') || id.startsWith('o1-') || id.startsWith('o3-') || id.startsWith('chatgpt-')
        })
        .map((model: any) => ({
          id: model.id,
          reasoning: isReasoningModel(model.id),
        }))

      return {
        success: true,
        models: chatModels,
      }
    } catch (error) {
      return {
        success: false,
        models: [],
        error: (error as Error).message || 'Network error',
      }
    }
  }

  /**
   * è·å– Google Gemini å¯ç”¨æ¨¡å‹åˆ—è¡¨
   * API æ–‡æ¡£: https://ai.google.dev/api/models
   * ç«¯ç‚¹: GET https://generativelanguage.googleapis.com/v1beta/models
   */
  static async fetchGoogleModels(apiKey: string): Promise<ModelsResult> {
    try {
      // Google API ä½¿ç”¨ API key ä½œä¸ºæŸ¥è¯¢å‚æ•°
      // è•¾å§†ä¿®å¤ï¼šä½¿ç”¨ v1beta è€Œä¸æ˜¯ v1
      const url = `https://generativelanguage.googleapis.com/v1beta/models?key=${apiKey}`

      const response = await fetch(url, {
        headers: {
          'Content-Type': 'application/json',
        },
      })

      if (!response.ok) {
        const error = await response.json().catch(() => ({}))
        return {
          success: false,
          models: [],
          error: error.error?.message || `HTTP ${response.status}`,
        }
      }

      const data = await response.json()

      // Google API è¿”å›æ ¼å¼: { models: [{ name, ... }] }
      // è•¾å§†è¿‡æ»¤å‡ºç”Ÿæˆæ¨¡å‹ï¼ˆgenerateContent ä¸º trueï¼‰
      const models: ModelInfo[] = (data.models || [])
        .filter((model: any) =>
          model.supportedGenerationMethods?.includes('generateContent')
        )
        .map((model: any) => {
          const id = model.name.replace('models/', '')
          return {
            id,
            reasoning: isReasoningModel(id),
          }
        })

      return {
        success: true,
        models,
      }
    } catch (error) {
      return {
        success: false,
        models: [],
        error: (error as Error).message || 'Network error',
      }
    }
  }

  /**
   * æ ¹æ®ä¾›åº”å•†ç±»å‹è·¯ç”±æ¨¡å‹è·å–
   */
  static async fetchModels(
    providerId: ProviderType,
    apiKey: string
  ): Promise<ModelsResult> {
    switch (providerId) {
      case 'deepseek':
        return this.fetchDeepSeekModels(apiKey)
      case 'openai':
        return this.fetchOpenAIModels(apiKey)
      case 'google':
        return this.fetchGoogleModels(apiKey)
      default:
        return {
          success: false,
          models: [],
          error: 'Unsupported provider for model fetching',
        }
    }
  }

  /**
   * è·å–å¤šä¸ªä¾›åº”å•†çš„æ¨¡å‹åˆ—è¡¨ï¼ˆå¹¶è¡Œè¯·æ±‚ï¼‰
   */
  static async fetchMultipleModels(
    providers: Array<{ providerId: ProviderType; apiKey: string }>
  ): Promise<Map<ProviderType, ModelsResult>> {
    const promises = providers.map(async ({ providerId, apiKey }) => {
      const result = await this.fetchModels(providerId, apiKey)
      return [providerId, result] as const
    })

    const results = await Promise.all(promises)
    return new Map(results)
  }
}
